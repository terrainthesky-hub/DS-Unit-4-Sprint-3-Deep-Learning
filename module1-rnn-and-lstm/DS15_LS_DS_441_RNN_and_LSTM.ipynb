{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "DS15 LS_DS_441_RNN_and_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7aRngz54AuC",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
        "<br></br>\n",
        "<br></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQzkWtUG4AuD",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_IizNKWLomoA"
      },
      "source": [
        "## Overview\n",
        "\n",
        "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
        "\n",
        "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
        "\n",
        "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
        "\n",
        "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "# Neural Networks for Sequences (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pT7nJzPe4AuE"
      },
      "source": [
        "## Overview\n",
        "\n",
        "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
        "\n",
        "$F_n = F_{n-1} + F_{n-2}$\n",
        "\n",
        "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
        "\n",
        "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
        "\n",
        "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
        "\n",
        "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
        "\n",
        "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
        "\n",
        "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
        "\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3qwSP-G24AuF"
      },
      "source": [
        "### RNN/LSTM Sentiment Classification with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ti23G0gRe3kr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "254ef709-3e05-43b2-b98d-abfe003a30f5"
      },
      "source": [
        "'''\n",
        "#Trains an LSTM model on the IMDB sentiment classification task.\n",
        "The dataset is actually too small for LSTM to be of any advantage\n",
        "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
        "**Notes**\n",
        "- RNNs are tricky. Choice of batch size is important,\n",
        "choice of loss and optimizer is critical, etc.\n",
        "Some configurations won't converge.\n",
        "- LSTM loss decrease patterns during training can be quite different\n",
        "from what you see with CNNs/MLPs/etc.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 120\n",
        "batch_size = 64\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmjWw8X84AuJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "119f86bd-236e-4bce-b0dc-a0c19985791f"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-GaT2-a4AuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f621c6de-9e7c-41e9-8297-66fc91848cc7"
      },
      "source": [
        "print('Pad Sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (25000, 120)\n",
            "x_test shape:  (25000, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucwbbXdD4AuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "999851ff-5363-4623-d002-d6567d02815a"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQkzp-Aq4AuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "47968cf7-272e-49eb-eb5a-da686ae6a5ca"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=.0001)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 64))\n",
        "model.add(tf.keras.layers.Bidirectional(LSTM(64)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=adam, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 64)          1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               66048     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,354,369\n",
            "Trainable params: 1,354,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyXNYukG4AuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "9f88a69b-aa07-49dd-cd22-3dc668d6c81b"
      },
      "source": [
        "unicorns2 = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size, \n",
        "          epochs=5, \n",
        "          validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 33s 83ms/step - loss: 0.5970 - accuracy: 0.6630 - val_loss: 0.4178 - val_accuracy: 0.8198\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 32s 81ms/step - loss: 0.3201 - accuracy: 0.8675 - val_loss: 0.3371 - val_accuracy: 0.8543\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 32s 81ms/step - loss: 0.2261 - accuracy: 0.9122 - val_loss: 0.3482 - val_accuracy: 0.8511\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 32s 81ms/step - loss: 0.1714 - accuracy: 0.9381 - val_loss: 0.3514 - val_accuracy: 0.8478\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 31s 80ms/step - loss: 0.1291 - accuracy: 0.9582 - val_loss: 0.4440 - val_accuracy: 0.8361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPdCHCQa4AuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "42ee4956-711f-4de6-e509-b31ac5c44fef"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(unicorns2.history['accuracy'])\n",
        "plt.plot(unicorns2.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw8WIKPM4AuZ",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7pETWPIe362y"
      },
      "source": [
        "# LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9m1xAU7h4AuZ"
      },
      "source": [
        "## Overview\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxy133Jq4Aua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUFRz_wc4Auc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "68bf8ae6-b95c-4591-849a-c69f9f61259f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/wp_articles.json\"\n",
        "df = pd.read_json(url)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>“The Queen’s Speech” is designed to acknowledg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Like an aging rock star, the president is now ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "10   Russian President Vladimir Putin speaks at a s...\n",
              "100  “The Queen’s Speech” is designed to acknowledg...\n",
              "101  Like an aging rock star, the president is now ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BordQl64Aue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in Data\n",
        "\n",
        "data = []\n",
        "\n",
        "for file in data_files:\n",
        "    if file[-3:] == 'txt':\n",
        "        with open(f'./articles/{file}', 'r', encoding='utf-8') as f:\n",
        "            data.append(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uE21rUN4Aug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwCQcOV44Aui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFinyz7_PZAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyyENHgk4Auk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(df['article'].values)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8uIid1x4Aum",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "041f7e5d-839d-488d-8ae1-e25e1ebb2bd3"
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRCjvP1r4Auo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec28fe4f-42e6-4f64-d7f0-4ad4ba113a48"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 1\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  891870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff3JGWpr4Auq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "96b520a3-3408-4246-c92b-acbc1973795d"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[71,\n",
              " 59,\n",
              " 52,\n",
              " 42,\n",
              " 78,\n",
              " 11,\n",
              " 25,\n",
              " 10,\n",
              " 42,\n",
              " 11,\n",
              " 52,\n",
              " 40,\n",
              " 34,\n",
              " 54,\n",
              " 59,\n",
              " 119,\n",
              " 10,\n",
              " 107,\n",
              " 52,\n",
              " 11,\n",
              " 44,\n",
              " 42,\n",
              " 30,\n",
              " 30,\n",
              " 12,\n",
              " 28,\n",
              " 15,\n",
              " 34,\n",
              " 79,\n",
              " 59,\n",
              " 10,\n",
              " 44,\n",
              " 15,\n",
              " 34,\n",
              " 11,\n",
              " 44,\n",
              " 34,\n",
              " 59,\n",
              " 52,\n",
              " 34]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXPVMDEv4Aut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "042d2mAY4Auv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92558e2a-3ab6-48ca-f411-b67cd898b6e9"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 40, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgzqIrtW4Aux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7596030-17fc-479d-9d06-4c47fc024134"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891870, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipGXPXBC4Auy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn7fV0sj4Au0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ePHYZY4Au2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "    \n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m4EQIll4Au4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f69bc3d2-8c93-4e28-a998-9ce3bb595cb7"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=256,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3482/3484 [============================>.] - ETA: 0s - loss: 1.8215\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"him the truth at that moment. “It’s only\"\n",
            "him the truth at that moment. “It’s only ay tailing the alfor weeks wan as worthing chaltes. Bulory blocks in the ternslog, at the Pran When the poogs you jovely walk feom, the Ridam, is alle.\n",
            "\n",
            "“You mondision was beabutees to polations, was sat what of Chomin, shinding forces and acned to bikg champat a.m. they’l reediers. Dnow Brow hows a “sice lon Agreatwarc jursed and timn to pereme the mam Subafitand by paise that seet that or incre\n",
            "3484/3484 [==============================] - 68s 20ms/step - loss: 1.8214\n",
            "Epoch 2/10\n",
            "3484/3484 [==============================] - ETA: 0s - loss: 1.7369\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"orarily moved to Washington and is on a \"\n",
            "orarily moved to Washington and is on a repintents in Bothist-movicing Wish that treitted your warted.\n",
            "\n",
            "In 3000 a, 2015.\n",
            "\n",
            "“TH Dentel Hady, when he was been the ider 1973 of wrote SyFianin’s decides and sioms Aunel ADdone. Rusplific mode the monchips paying, and Ungain; on AxCisipenfor Alona Carrena in thowe when hatment ullardews to the andiend is a which Ollitary Heaten 200 and, at Bessishal Deprones policaul “Putona’s growmenting & Si\n",
            "3484/3484 [==============================] - 67s 19ms/step - loss: 1.7369\n",
            "Epoch 3/10\n",
            "3481/3484 [============================>.] - ETA: 0s - loss: 1.6766\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"s in the air, chasing balls and racing a\"\n",
            "s in the air, chasing balls and racing ang expended by Menvol Vaige said off prownng from the Dep.t the islare leading Chenf. Warger. Patter, he U.S. and that on the Steele (@fonshy) after a “Weigh, an orlauativar rimes wey not gitt’ command to take years,’s Adiets and Nollication. That clean coserall’s istose fontment held using to the Becdor had mificy to me by gon't in my “It.\n",
            "\n",
            "Fith stary expents and string on or left been diring so \n",
            "3484/3484 [==============================] - 67s 19ms/step - loss: 1.6766\n",
            "Epoch 4/10\n",
            "3484/3484 [==============================] - ETA: 0s - loss: 1.6311\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \" hour, reports have been cautiously opti\"\n",
            " hour, reports have been cautiously option my stencl we sure, as a lurtial said. Every of a opheess heldame with The Washington sogror oni it a stryters that is other, Kuase has steal cestule as prossuinated and fonced though-election, 36-beceming intereate to face adminitaits crasted. Cheft were now, roodinaby Abrain and Spuir insposed to befone the puscour are the 199arlay, and the dur defending exartous demotra, asked the abous said \n",
            "3484/3484 [==============================] - 67s 19ms/step - loss: 1.6311\n",
            "Epoch 5/10\n",
            "3484/3484 [==============================] - ETA: 0s - loss: 1.5955\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"e:\n",
            "\n",
            "Immigrants arrive with flourishing g\"\n",
            "e:\n",
            "\n",
            "Immigrants arrive with flourishing govern known with siburing four depertent, personalises all the man and treests incuss to only, the president on Aurd nothelteck explayes right with the psopos differeating oppenesion, he will day joines, and cormpeach, Raice Washington to her are Iffice as the 61, internotion. Schiollage’s expept attirn political posseting for, or hereagents are storplest of file dreakly that modely great, edical \n",
            "3484/3484 [==============================] - 67s 19ms/step - loss: 1.5955\n",
            "Epoch 6/10\n",
            "2515/3484 [====================>.........] - ETA: 15s - loss: 1.5691"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-769734b7cf05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=[print_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zId4HuZ4Au6",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccjVO6ZAUkyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se_B_qdQUmg-",
        "colab_type": "text"
      },
      "source": [
        "# Use Tensor Dataset for TPU Acceleration! :D \n",
        "\n",
        "*   Create a TensorFlow Dataset\n",
        "*   Attempt to use experimential TPUs from Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpbYZM94VJsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "data = tf.data.Dataset.from_tensor_slices(x)\n",
        "target = tf.data.Dataset.from_tensor_slices(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ioIzz3vVhaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.zip((data, target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PKcURwdVtOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batched_Dataset = dataset.batch(256, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nb9T11yWMzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb413bf5-3dc4-43e1-f8bf-f1f1cfa0f5c5"
      },
      "source": [
        "try:\n",
        "  device_name = os.environ[\"COLAB_TPU_ADDR\"]\n",
        "  TPU_ADDRESS = \"grpc://\" + device_name\n",
        "  print(\"Found TPU at: {}\".format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        "  print(\"TPU not found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TPU at: grpc://10.62.15.218:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTRBEQW7XO2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFpYTVTBXRWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "44d19128-d9e6-4feb-f52a-90076ea87598"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.62.15.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.62.15.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZHJUaV0XzjG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "4d247825-7bc3-4d8a-b794-b77e8250aa08"
      },
      "source": [
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayRj45UJX2dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "  model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='nadam')\n",
        "\n",
        "  model.fit(batched_Dataset,\n",
        "            steps_per_epoch = x.shape[0] // 256,\n",
        "            epochs=10,\n",
        "            callbacks=[print_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLCasfaH4Au7",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Time Series (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - And many more! :D\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
        "    * Shape of input data is very important\n",
        "    * Can take a while to train\n",
        "    * You can use it to write movie scripts. :P "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT3gAl5IY0zZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}